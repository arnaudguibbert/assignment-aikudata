{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning & preprocessing\n",
    "\n",
    "This notebook contain all the steps we performed during the data cleaning and preprocessing. Before running this notebook, make sure you read the [README.md](../README.md) file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from assaiku.data import DataConfig, DataPipe\n",
    "from assaiku.data.validation import load_and_validate\n",
    "from assaiku.data.processing import remove_group_duplicates, filter_outliers\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "\n",
    "data_config = DataConfig(perform_exploration=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and validating data\n",
    "\n",
    "First we load the data and validate it, for validation we are using the `pandera` library that will check several things:\n",
    "- the data type of each column\n",
    "- numerical constraints (for instance `age >= 0`)\n",
    "- nategorical constraints (for instance ``sex is in [Male, Female]``)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = load_and_validate(data_config=data_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing duplicates\n",
    "\n",
    "Here are the operations we are performing:\n",
    "- We remove some duplicates (including the instance group)\n",
    "- Then we group the same instances together and sum their ``instance_weights``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = remove_group_duplicates(train_df, weight_col=data_config.weight_col)\n",
    "test_df = remove_group_duplicates(test_df, weight_col=data_config.weight_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for outliers\n",
    "\n",
    "We are checking for outliers, to do so we will use the *Empirical Cumulative Distribution-based Outlier Detection (ECOD)* method on continuous feature: \n",
    "- The distribution of outlier scores is displayed\n",
    "- An example of outlier is given too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train, clean_test = filter_outliers(\n",
    "    train_data=train_df,\n",
    "    test_data=test_df,\n",
    "    numerical_cols=data_config.numerical_cols,\n",
    "    threshold=data_config.threshold_outlier,\n",
    "    folder_path=\"./preprocessing\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train.to_parquet(data_config.train_data_out)\n",
    "clean_test.to_parquet(data_config.test_data_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running all the previous step in one line\n",
    "\n",
    "The data cleaning and processing pipeline is part of the data pipeline, you can run all previous steps running the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = DataConfig(perform_exploration=False)\n",
    "data_pipeline = DataPipe(data_config=data_config)\n",
    "data_pipeline.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
