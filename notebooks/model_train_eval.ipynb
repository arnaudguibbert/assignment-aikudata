{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from assaiku.data import DataConfig\n",
    "\n",
    "from assaiku.model.configs import EvaluationConfig\n",
    "from assaiku.model.evaluation import evaluate_model\n",
    "from assaiku.model.processors import (\n",
    "    fit_processor,\n",
    "    initialize_feat_processor,\n",
    "    split_transform,\n",
    ")\n",
    "from assaiku.model.train import initialize_model, train_model\n",
    "from assaiku.model.evaluation import analyze_data\n",
    "from assaiku.model.configs import LogisticRegressionConfig, EvaluationConfig, LinearSVMConfig, XGBConfig\n",
    "from assaiku.model import MLPipe\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "data_config = DataConfig(perform_exploration=True)\n",
    "model_config = XGBConfig(n_estimators=100,\n",
    "        max_depth=7,\n",
    "        learning_rate=1e-1,\n",
    "        dimension_red=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data generated by Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_parquet(path=data_config.train_data_out)\n",
    "test_data = pd.read_parquet(path=data_config.test_data_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiliaze the data processor and fit it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_processor, label_binarizer = initialize_feat_processor(\n",
    "                data_config=data_config, model_config=model_config\n",
    "            )\n",
    "fit_processor(\n",
    "    train_data=train_data,\n",
    "    feature_cols=data_config.features,\n",
    "    pipeline=feat_processor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split and transform data for each data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, w_train = split_transform(\n",
    "                train_data,\n",
    "                feat_processor,\n",
    "                label_binarizer,\n",
    "                data_config=data_config,\n",
    "            )\n",
    "x_test, y_test, w_test = split_transform(\n",
    "    test_data,\n",
    "    feat_processor,\n",
    "    label_binarizer,\n",
    "    data_config=data_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = initialize_model(model_config=model_config)\n",
    "\n",
    "train_model(\n",
    "    model_config=model_config,\n",
    "    x_train=x_train,\n",
    "    y_train=y_train,\n",
    "    weights=w_train,\n",
    "    model=model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_perf_0, train_perf_1 = evaluate_model(\n",
    "    model=model,\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    weights=w_train,\n",
    "    data_set=\"train\",\n",
    "    model_name=model_config.name,\n",
    ")\n",
    "\n",
    "test_perf_0, test_perf_1 = evaluate_model(\n",
    "    model=model,\n",
    "    x=x_test,\n",
    "    y=y_test,\n",
    "    weights=w_test,\n",
    "    data_set=\"test\",\n",
    "    model_name=model_config.name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare different models in one line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify your evaluation config here\n",
    "eval_config = EvaluationConfig(n_repet=2,\n",
    "                            model_configs=[\n",
    "                                XGBConfig(n_estimators=100,\n",
    "                                            max_depth=7,\n",
    "                                            learning_rate=1e-1,\n",
    "                                            dimension_red=None),\n",
    "                                XGBConfig(weight_neg_factor=1, \n",
    "                                            weight_pos_factor=1,\n",
    "                                            dimension_red=50),\n",
    "                                LinearSVMConfig(rbf_gamma=5e-5, C=100),\n",
    "                                LinearSVMConfig(),\n",
    "                                LogisticRegressionConfig(),\n",
    "                                LogisticRegressionConfig(dimension_red=50),\n",
    "                            ])\n",
    "\n",
    "ml_pipeline = MLPipe(data_config=data_config,\n",
    "                     evaluation_config=eval_config)\n",
    "\n",
    "data = ml_pipeline.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
