{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "\n",
    "This notebook contain all the steps we performed during the data exploration phase. Before running this notebook, make sure you read the [README.md](../README.md) file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from assaiku.data import DataConfig, DataPipe\n",
    "from assaiku.data.validation import load_and_validate\n",
    "from assaiku.data.exploration import (\n",
    "    visualize_categorical_dist, \n",
    "    visualize_continuous_dist, \n",
    "    visualize_correlation,\n",
    "    analyze_nans, \n",
    "    analyze_label_dist,\n",
    "    visualize_distance\n",
    ")\n",
    "from assaiku.data.processing import remove_group_duplicates, filter_on_age\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "data_config = DataConfig(perform_exploration=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and validating data\n",
    "\n",
    "First we load the data and validate it, for validation we are using the `pandera` library that will check several things:\n",
    "- the data type of each column\n",
    "- numerical constraints (for instance `age >= 0`)\n",
    "- nategorical constraints (for instance ``sex is in [Male, Female]``)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = load_and_validate(data_config=data_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some data cleaning\n",
    "\n",
    "Before the analysis we will check several things:\n",
    "- The missing values in the dataset\n",
    "- The duplicates\n",
    "- Filtering out some rows that may bias the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values\n",
    "\n",
    "Do we have nay missing values in our datasets ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Analyze nans in train dataframe\")\n",
    "analyze_nans(train_df)\n",
    "print(\"Analyze nans in test dataframe\")\n",
    "analyze_nans(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing duplicates\n",
    "\n",
    "Here are the operations we are performing:\n",
    "- We remove some duplicates (including the instance group)\n",
    "- Then we group the same instances together and sum their ``instance_weights``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train_df = remove_group_duplicates(train_df,weight_col=data_config.weight_col)\n",
    "clean_test_df = remove_group_duplicates(test_df,weight_col=data_config.weight_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Let's first have a look at our distribution of labels in each data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the distribution of labels\n",
    "print(\"Train\")\n",
    "analyze_label_dist(data=clean_train_df, data_config=data_config)\n",
    "print(\"Test\")\n",
    "analyze_label_dist(data=clean_test_df, data_config=data_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering out some rows\n",
    "\n",
    "To not bias the analysis, we filtered out some rows based on the age. We filtered out children (``age < 16``) as they would bias the statistics (we checked that all those children have an income lower than 50k-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train_df = filter_on_age(clean_train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D analysis of continuous features\n",
    "\n",
    "To know if there exist any correlation between any continuous feature and the income, we ran the following analysis:\n",
    "- Computation of the correlation coefficient between the feature and the income\n",
    "- Visualization of the distribution for each group (50k+,50k-). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_correlation(data=clean_train_df,\n",
    "                      data_config=data_config,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_continuous_dist(data=clean_train_df,\n",
    "                          data_config=data_config,\n",
    "                          folder_path=\"results/exploration/continuous\",\n",
    "                          filter_cols=None,\n",
    "                          close_figs=False,\n",
    "                          # filter_cols=[\"age\",\"wage_per_hour\"],\n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D analysis of categorical features\n",
    "\n",
    "To know if there exist any difference in the two groups in the distribution of values within each category we looked at the following things:\n",
    "- For each category, the distance between the two distributions (we used wassertein distance)\n",
    "- Visualization of the distribution of values for each group (50k+,50k-) and for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_distance(data=clean_train_df, data_config=data_config, truncate=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_categorical_dist(data=clean_train_df, \n",
    "                           data_config=data_config, \n",
    "                           folder_path=\"results/exploration/categorical\",\n",
    "                           close_figs=False,\n",
    "                           filter_cols=[\"detailed_industry_recode\",\n",
    "                           \"sex\",\n",
    "                           \"detailed_household_summary_in_household\", \n",
    "                           \"major_occupation_code\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running all the previous step in one line\n",
    "\n",
    "The data exploration pipeline is part of the data pipeline, you can run all previous steps running the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = DataConfig(perform_exploration=True)\n",
    "data_pipeline = DataPipe(data_config=data_config)\n",
    "data_pipeline.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
